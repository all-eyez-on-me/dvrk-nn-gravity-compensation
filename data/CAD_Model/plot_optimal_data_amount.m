% Solve an Input-Output Fitting problem with a Neural Network
% Script generated by Neural Fitting app
% Created 03-Aug-2019 08:28:09
%
% This script assumes these variables are defined:
%
%   input_mat - input data.
%   output_mat_1 - target data.

x = input_mat;
t = output_mat(5,:);


optimal_neuron_num = 9;

%data_ratio_list = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5];
data_ratio_list = logspace(-4,0,10);

% Choose a Training Function
% For a list of all training functions type: help nntrain
% 'trainlm' is usually fastest.
% 'trainbr' takes longer but may be better for challenging problems.
% 'trainscg' uses less memory. Suitable in low memory situations.
trainFcn = 'trainlm';  % Levenberg-Marquardt backpropagation.

train_perform_list = [];
validation_perform_list = [];
test_perform_list = [];
tr_stop_list = {};
% Create a Fitting Network
hiddenLayerSize = optimal_neuron_num;
net = fitnet(hiddenLayerSize,trainFcn);

% Choose Input and Output Pre/Post-Processing Functions
% For a list of all processing functions type: help nnprocess
net.input.processFcns = {'removeconstantrows','mapminmax'};
net.output.processFcns = {'removeconstantrows','mapminmax'};

% Setup Division of Data for Training, Validation, Testing
% For a list of all data division functions type: help nndivision
net.divideFcn = 'dividerand';  % Divide data randomly
net.divideMode = 'sample';  % Divide up every sample
net.divideParam.trainRatio = 70/100;
net.divideParam.valRatio = 15/100;
net.divideParam.testRatio = 15/100;

% Choose a Performance Function
% For a list of all performance functions type: help nnperformance
net.performFcn = 'mse';  % Mean Squared Error

% Choose Plot Functions
% For a list of all plot functions type: help nnplot
net.plotFcns = {'plotperform','plottrainstate','ploterrhist', ...
    'plotregression'};

% Train the Network
 net.trainParam.goal = 1e-10;
net.trainParam.showWindow = false;
net.trainParam.showCommandLine = true;
net.trainParam.max_fail = 4;


for i = data_ratio_list
    data_amount = round(i*size(x,2));
    x_input = x(:,1:data_amount);
    t_input = t(:,1:data_amount);
    [net,tr] = train(net,x_input,t_input);

    % Test the Network
    y = net(x_input);
    e = gsubtract(t_input,y);
    performance = perform(net,t_input,y);

    % Recalculate Training, Validation and Test Performance
    trainTargets = t_input .* tr.trainMask{1};
    valTargets = t_input .* tr.valMask{1};
    testTargets = t_input .* tr.testMask{1};
    trainPerformance = perform(net,trainTargets,y)
    train_perform_list = [train_perform_list, trainPerformance];
    valPerformance = perform(net,valTargets,y)
    validation_perform_list = [validation_perform_list,valPerformance];
    testPerformance = perform(net,testTargets,y)
    test_perform_list = [test_perform_list, testPerformance];
    tr_stop_list{end+1} = tr.stop; 
end


%%

figure
hold on
x_lim_max = max(data_ratio_list*size(input_mat,2))*1.2;
y_lim_min = min(test_perform_list)*0.8e-1;
y_lim_max = 1e-2;
plot(data_ratio_list*size(input_mat,2), test_perform_list,'-ok',...
'LineWidth',2,...
'MarkerFaceColor','b',...
'MarkerSize',10)
set(gca, 'XScale', 'log')
set(gca, 'YScale', 'log')
set(gca,'FontSize',20)
xlabel('data amount');
ylabel('E_{RMS}');
xlim([0,x_lim_max])
ylim([y_lim_min,y_lim_max])




optimal_neuron_index = 9;
% plot([optimal_neuron_index,optimal_neuron_index],[0, y_lim_max],'--k','LineWidth',2)
hold off

